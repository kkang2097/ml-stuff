{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e64b49f",
   "metadata": {},
   "source": [
    "# Neural Probabilistic Language Model (Yoshua Bengio et. al)\n",
    "\n",
    "- Goal: We need to encode natural language into vector space\n",
    "- Solution: Implement NPLM model\n",
    "\n",
    "### Outline\n",
    "- Basics\n",
    "    - What is a probabilistic model of language?\n",
    "    - ...other questions...\n",
    "- Defining a NN model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0fe9743",
   "metadata": {},
   "source": [
    "### Basics\n",
    "\n",
    "It may be unclear whether we can even map natural language to a vector space. This paper attempts this (and does pretty well). But we need some definitions.\n",
    "\n",
    "#### What is a probabilistic model of language?\n",
    "\n",
    "A statistical model of language can be represented by: the conditional probability of the next word, given all the previous words\n",
    "\n",
    "$$ \\hat{P}(w_{1}^{T}) = \\prod_{t=1}^{T} \\hat{P}(w_t | w_{1}^{t-1})$$\n",
    "where\n",
    "- $T$ is the number of words\n",
    "- $w$ is a word"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1fbc146",
   "metadata": {},
   "source": [
    "**Note:** Bengio's 2003 paper uses explicit calculation of the conditional probabilities, but it's much faster these days to instead use heirarchical softmax instead of softmax. (Since you traverse a binary tree instead of using exponential function)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8fb0334",
   "metadata": {},
   "source": [
    "Some things to think about\n",
    "- Do we always need a corpus of words?\n",
    "- What happens when we encounter a new set of words not in the corpus? (ie. \"Dog was running in the bedroom\" inside training data, then encountering \"Cat was running in the garage\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c11b438f",
   "metadata": {},
   "source": [
    "### Defining a Neural Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf46a24",
   "metadata": {},
   "source": [
    "- Training set: made up of words $\\{w_1 ... w_t, \\forall w_t \\in V\\}$\n",
    "- Input: All the previous words of the sequence\n",
    "- Output: Predicting the last word of the sequence\n",
    "- Objective: $f(w_1 ... w_t) = \\hat{P}(w_t | w_{1}^{t-1})$\n",
    "- Mapping: embeddings -> vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3118dc01",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to /home/kkang2097/nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /home/kkang2097/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import csv\n",
    "import numpy as np\n",
    "\n",
    "#If we don't have the relevant corpus (corpora in plural),\n",
    "#download them\n",
    "try:\n",
    "    nltk.data.find('corpora/brown')\n",
    "    nltk.data.find('corpora/wordnet')\n",
    "except LookupError:\n",
    "    nltk.download('brown')\n",
    "    nltk.download('wordnet')    \n",
    "\n",
    "from nltk.corpus import brown\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "#Boilerplate pre-processing\n",
    "num_train = 1000\n",
    "UNK_symbol = \"<UNK>\"\n",
    "vocab = set([UNK_symbol])\n",
    "\n",
    "# create brown corpus again with all words\n",
    "# no preprocessing, only lowercase\n",
    "brown_corpus_train = []\n",
    "for idx,paragraph in enumerate(brown.paras()):\n",
    "    if idx == num_train:\n",
    "        break\n",
    "    words = []\n",
    "    for sentence in paragraph:\n",
    "        for word in sentence:\n",
    "            words.append(word.lower())\n",
    "    brown_corpus_train.append(words)\n",
    "\n",
    "# create term frequency of the words\n",
    "words_term_frequency_train = {}\n",
    "for doc in brown_corpus_train:\n",
    "    for word in doc:\n",
    "        # this will calculate term frequency\n",
    "        # since we are taking all words now\n",
    "        words_term_frequency_train[word] = words_term_frequency_train.get(word,0) + 1\n",
    "\n",
    "# create vocabulary\n",
    "for doc in brown_corpus_train:\n",
    "    for word in doc:\n",
    "        if words_term_frequency_train.get(word,0) >= 5:\n",
    "            vocab.add(word)\n",
    "\n",
    "# create required lists\n",
    "x_train = []\n",
    "y_train = []\n",
    "x_dev = []\n",
    "y_dev = []\n",
    "\n",
    "# create word to id mappings\n",
    "word_to_id_mappings = {}\n",
    "for idx,word in enumerate(vocab):\n",
    "    word_to_id_mappings[word] = idx\n",
    "\n",
    "# function to get id for a given word\n",
    "# return <UNK> id if not found\n",
    "def get_id_of_word(word):\n",
    "    unknown_word_id = word_to_id_mappings['<UNK>']\n",
    "    return word_to_id_mappings.get(word,unknown_word_id)\n",
    "\n",
    "# creating training and dev set\n",
    "for idx,paragraph in enumerate(brown.paras()):\n",
    "    for sentence in paragraph:\n",
    "        for i,word in enumerate(sentence):\n",
    "            if i+2 >= len(sentence):\n",
    "                # sentence boundary reached\n",
    "                # ignoring sentence less than 3 words\n",
    "                break\n",
    "            # convert word to id\n",
    "            x_extract = [get_id_of_word(word.lower()),get_id_of_word(sentence[i+1].lower())]\n",
    "            y_extract = [get_id_of_word(sentence[i+2].lower())]\n",
    "            if idx < num_train:\n",
    "                x_train.append(x_extract)\n",
    "                y_train.append(y_extract)\n",
    "            else:\n",
    "                x_dev.append(x_extract)\n",
    "                y_dev.append(y_extract)\n",
    "\n",
    "# making numpy arrays\n",
    "x_train = np.array(x_train)\n",
    "y_train = np.array(y_train)\n",
    "x_dev = np.array(x_dev)\n",
    "y_dev = np.array(y_dev)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a8ed9801",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Copy pasting tri-gram NPLM\n",
    "#link: https://abhinavcreed13.github.io/blog/bengio-trigram-nplm-using-pytorch/\n",
    "import torch\n",
    "import multiprocessing\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import time\n",
    "\n",
    "# Trigram Neural Network Model\n",
    "class TrigramNNmodel(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size, embedding_dim, context_size, h):\n",
    "        super(TrigramNNmodel, self).__init__()\n",
    "        self.context_size = context_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.linear1 = nn.Linear(context_size * embedding_dim, h)\n",
    "        self.linear2 = nn.Linear(h, vocab_size, bias = False)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        # compute x': concatenation of x1 and x2 embeddings\n",
    "        embeds = self.embeddings(inputs).view((-1,self.context_size * self.embedding_dim))\n",
    "        # compute h: tanh(W_1.x' + b)\n",
    "        out = torch.tanh(self.linear1(embeds))\n",
    "        # compute W_2.h\n",
    "        out = self.linear2(out)\n",
    "        # compute y: log_softmax(W_2.h)\n",
    "        log_probs = F.log_softmax(out, dim=1)\n",
    "        # return log probabilities\n",
    "        # BATCH_SIZE x len(vocab)\n",
    "        return log_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "54f0b3bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Creating training and dev dataloaders with 64 batch size ---\n"
     ]
    }
   ],
   "source": [
    "# create parameters\n",
    "gpu = 0 \n",
    "# word vectors size\n",
    "EMBEDDING_DIM = 200\n",
    "CONTEXT_SIZE = 2\n",
    "BATCH_SIZE = 64\n",
    "# hidden units\n",
    "H = 100\n",
    "torch.manual_seed(13013)\n",
    "\n",
    "# check if gpu is available\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "available_workers = multiprocessing.cpu_count()\n",
    "\n",
    "print(\"--- Creating training and dev dataloaders with {} batch size ---\".format(BATCH_SIZE))\n",
    "train_set = np.concatenate((x_train, y_train), axis=1)\n",
    "dev_set = np.concatenate((x_dev, y_dev), axis=1)\n",
    "train_loader = DataLoader(train_set, batch_size = BATCH_SIZE, num_workers = available_workers)\n",
    "dev_loader = DataLoader(dev_set, batch_size = BATCH_SIZE, num_workers = available_workers)\n",
    "\n",
    "def get_accuracy_from_log_probs(log_probs, labels):\n",
    "    probs = torch.exp(log_probs)\n",
    "    predicted_label = torch.argmax(probs, dim=1)\n",
    "    acc = (predicted_label == labels).float().mean()\n",
    "    return acc\n",
    "\n",
    "# helper function to evaluate model on dev data\n",
    "def evaluate(model, criterion, dataloader, gpu):\n",
    "    model.eval()\n",
    "\n",
    "    mean_acc, mean_loss = 0, 0\n",
    "    count = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        dev_st = time.time()\n",
    "        for it, data_tensor in enumerate(dataloader):\n",
    "            context_tensor = data_tensor[:,0:2]\n",
    "            target_tensor = data_tensor[:,2]\n",
    "            context_tensor, target_tensor = context_tensor.cuda(gpu), target_tensor.cuda(gpu)\n",
    "            log_probs = model(context_tensor)\n",
    "            mean_loss += criterion(log_probs, target_tensor).item()\n",
    "            mean_acc += get_accuracy_from_log_probs(log_probs, target_tensor)\n",
    "            count += 1\n",
    "            if it % 500 == 0: \n",
    "                print(\"Dev Iteration {} complete. Mean Loss: {}; Mean Acc:{}; Time taken (s): {}\".format(it, mean_loss / count, mean_acc / count, (time.time()-dev_st)))\n",
    "                dev_st = time.time()\n",
    "\n",
    "    return mean_acc / count, mean_loss / count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "372ac6a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Training model Epoch: 1 ---\n",
      "Training Iteration 0 of epoch 0 complete. Loss: 7.127009868621826; Acc:0.0; Time taken (s): 5.275617599487305\n",
      "Training Iteration 500 of epoch 0 complete. Loss: 3.044797658920288; Acc:0.453125; Time taken (s): 0.9444775581359863\n",
      "\n",
      "--- Evaluating model on dev data ---\n",
      "Dev Iteration 0 complete. Mean Loss: 3.8231685161590576; Mean Acc:0.3125; Time taken (s): 0.33402490615844727\n",
      "Dev Iteration 500 complete. Mean Loss: 3.9175908646421758; Mean Acc:0.2960641086101532; Time taken (s): 0.47676587104797363\n",
      "Dev Iteration 1000 complete. Mean Loss: 4.007392706809106; Mean Acc:0.2820460796356201; Time taken (s): 0.44428467750549316\n",
      "Dev Iteration 1500 complete. Mean Loss: 4.03563623329864; Mean Acc:0.27701324224472046; Time taken (s): 0.48658299446105957\n",
      "Dev Iteration 2000 complete. Mean Loss: 3.9877283239531436; Mean Acc:0.2819918096065521; Time taken (s): 0.48996925354003906\n",
      "Dev Iteration 2500 complete. Mean Loss: 3.948182597535937; Mean Acc:0.2864229381084442; Time taken (s): 0.5141799449920654\n",
      "Dev Iteration 3000 complete. Mean Loss: 3.9451196302536604; Mean Acc:0.2868887484073639; Time taken (s): 0.5146880149841309\n",
      "Dev Iteration 3500 complete. Mean Loss: 3.915194279805009; Mean Acc:0.29025188088417053; Time taken (s): 0.48224735260009766\n",
      "Dev Iteration 4000 complete. Mean Loss: 3.9099118918724223; Mean Acc:0.2918645441532135; Time taken (s): 0.4877324104309082\n",
      "Dev Iteration 4500 complete. Mean Loss: 3.9124942481636973; Mean Acc:0.2920045554637909; Time taken (s): 0.518218994140625\n",
      "Dev Iteration 5000 complete. Mean Loss: 3.905829413798637; Mean Acc:0.2926383316516876; Time taken (s): 0.52065110206604\n",
      "Dev Iteration 5500 complete. Mean Loss: 3.8972934813222935; Mean Acc:0.29294106364250183; Time taken (s): 0.49437737464904785\n",
      "Dev Iteration 6000 complete. Mean Loss: 3.898309782095262; Mean Acc:0.29255542159080505; Time taken (s): 0.5488598346710205\n",
      "Dev Iteration 6500 complete. Mean Loss: 3.889315344080377; Mean Acc:0.2932433485984802; Time taken (s): 0.5071671009063721\n",
      "Dev Iteration 7000 complete. Mean Loss: 3.8903179990446684; Mean Acc:0.29309651255607605; Time taken (s): 0.5369884967803955\n",
      "Dev Iteration 7500 complete. Mean Loss: 3.8903010584420956; Mean Acc:0.2929234206676483; Time taken (s): 0.6438953876495361\n",
      "Dev Iteration 8000 complete. Mean Loss: 3.8880692739633305; Mean Acc:0.29283252358436584; Time taken (s): 0.5226650238037109\n",
      "Dev Iteration 8500 complete. Mean Loss: 3.8921275989488495; Mean Acc:0.2925446331501007; Time taken (s): 0.5403256416320801\n",
      "Dev Iteration 9000 complete. Mean Loss: 3.897464226542705; Mean Acc:0.2918599247932434; Time taken (s): 0.4895460605621338\n",
      "Dev Iteration 9500 complete. Mean Loss: 3.87911049803487; Mean Acc:0.29373061656951904; Time taken (s): 0.5293741226196289\n",
      "Dev Iteration 10000 complete. Mean Loss: 3.8688904836933298; Mean Acc:0.29482364654541016; Time taken (s): 0.483243465423584\n",
      "Dev Iteration 10500 complete. Mean Loss: 3.8716474252364237; Mean Acc:0.2944466769695282; Time taken (s): 0.48117923736572266\n",
      "Dev Iteration 11000 complete. Mean Loss: 3.87604322172102; Mean Acc:0.29435110092163086; Time taken (s): 0.48420071601867676\n",
      "Dev Iteration 11500 complete. Mean Loss: 3.8662215311126538; Mean Acc:0.29541996121406555; Time taken (s): 0.4882783889770508\n",
      "Dev Iteration 12000 complete. Mean Loss: 3.8617809805191814; Mean Acc:0.2957409918308258; Time taken (s): 0.5812201499938965\n",
      "Dev Iteration 12500 complete. Mean Loss: 3.8633074416378843; Mean Acc:0.2954976260662079; Time taken (s): 0.5078136920928955\n",
      "Dev Iteration 13000 complete. Mean Loss: 3.8736124833486016; Mean Acc:0.29419732093811035; Time taken (s): 0.4800388813018799\n",
      "Dev Iteration 13500 complete. Mean Loss: 3.8805779541574505; Mean Acc:0.2933879792690277; Time taken (s): 0.4703521728515625\n",
      "Dev Iteration 14000 complete. Mean Loss: 3.8833557605981808; Mean Acc:0.29291993379592896; Time taken (s): 0.48978352546691895\n",
      "Dev Iteration 14500 complete. Mean Loss: 3.8849794445560026; Mean Acc:0.29273736476898193; Time taken (s): 0.5029537677764893\n",
      "Dev Iteration 15000 complete. Mean Loss: 3.890544327932408; Mean Acc:0.29203468561172485; Time taken (s): 0.5065810680389404\n",
      "Dev Iteration 15500 complete. Mean Loss: 3.8970306673616557; Mean Acc:0.29129067063331604; Time taken (s): 0.515514612197876\n",
      "Epoch 0 complete! Development Accuracy: 0.29127922654151917; Development Loss: 3.8973257141046864\n",
      "Best development accuracy improved from 0 to 0.29127922654151917, saving model...\n",
      "\n",
      "--- Training model Epoch: 2 ---\n",
      "Training Iteration 0 of epoch 1 complete. Loss: 4.681087017059326; Acc:0.140625; Time taken (s): 0.2788839340209961\n",
      "Training Iteration 500 of epoch 1 complete. Loss: 2.9305999279022217; Acc:0.4375; Time taken (s): 0.8817780017852783\n",
      "\n",
      "--- Evaluating model on dev data ---\n",
      "Dev Iteration 0 complete. Mean Loss: 3.7126715183258057; Mean Acc:0.3125; Time taken (s): 0.31818723678588867\n",
      "Dev Iteration 500 complete. Mean Loss: 3.854865286164655; Mean Acc:0.2848365902900696; Time taken (s): 0.45145130157470703\n",
      "Dev Iteration 1000 complete. Mean Loss: 3.94811432261567; Mean Acc:0.27278971672058105; Time taken (s): 0.463547945022583\n",
      "Dev Iteration 1500 complete. Mean Loss: 3.9751821414857287; Mean Acc:0.27031978964805603; Time taken (s): 0.4806082248687744\n",
      "Dev Iteration 2000 complete. Mean Loss: 3.9295030665481048; Mean Acc:0.27513587474823; Time taken (s): 0.46625804901123047\n",
      "Dev Iteration 2500 complete. Mean Loss: 3.8919840145473334; Mean Acc:0.27831366658210754; Time taken (s): 0.46184849739074707\n",
      "Dev Iteration 3000 complete. Mean Loss: 3.8899367801430462; Mean Acc:0.2793391942977905; Time taken (s): 0.47077250480651855\n",
      "Dev Iteration 3500 complete. Mean Loss: 3.8617040903627515; Mean Acc:0.28128570318222046; Time taken (s): 0.46152639389038086\n",
      "Dev Iteration 4000 complete. Mean Loss: 3.8563918823362795; Mean Acc:0.28230443596839905; Time taken (s): 0.4596078395843506\n",
      "Dev Iteration 4500 complete. Mean Loss: 3.858443958100889; Mean Acc:0.28239905834198; Time taken (s): 0.466937780380249\n",
      "Dev Iteration 5000 complete. Mean Loss: 3.851754143604682; Mean Acc:0.28335583209991455; Time taken (s): 0.4724736213684082\n",
      "Dev Iteration 5500 complete. Mean Loss: 3.842992472163202; Mean Acc:0.2836586534976959; Time taken (s): 0.47925591468811035\n",
      "Dev Iteration 6000 complete. Mean Loss: 3.844364084634875; Mean Acc:0.28373396396636963; Time taken (s): 0.47375917434692383\n",
      "Dev Iteration 6500 complete. Mean Loss: 3.83555147400674; Mean Acc:0.2846004366874695; Time taken (s): 0.4806997776031494\n",
      "Dev Iteration 7000 complete. Mean Loss: 3.8363353051452735; Mean Acc:0.28462451696395874; Time taken (s): 0.4772379398345947\n",
      "Dev Iteration 7500 complete. Mean Loss: 3.836074853973251; Mean Acc:0.28441205620765686; Time taken (s): 0.4800448417663574\n",
      "Dev Iteration 8000 complete. Mean Loss: 3.833700406657146; Mean Acc:0.2846538722515106; Time taken (s): 0.550438404083252\n",
      "Dev Iteration 8500 complete. Mean Loss: 3.8378388575561857; Mean Acc:0.2843691110610962; Time taken (s): 0.4695568084716797\n",
      "Dev Iteration 9000 complete. Mean Loss: 3.843226176012279; Mean Acc:0.28415244817733765; Time taken (s): 0.46444106101989746\n",
      "Dev Iteration 9500 complete. Mean Loss: 3.8250826809509415; Mean Acc:0.2860258221626282; Time taken (s): 0.466158390045166\n",
      "Dev Iteration 10000 complete. Mean Loss: 3.8150554453655547; Mean Acc:0.28702598810195923; Time taken (s): 0.47423410415649414\n",
      "Dev Iteration 10500 complete. Mean Loss: 3.8181528699203917; Mean Acc:0.2868923246860504; Time taken (s): 0.47786688804626465\n",
      "Dev Iteration 11000 complete. Mean Loss: 3.8227514750241647; Mean Acc:0.28686314821243286; Time taken (s): 0.4818403720855713\n",
      "Dev Iteration 11500 complete. Mean Loss: 3.812867991945638; Mean Acc:0.28785812854766846; Time taken (s): 0.4819512367248535\n",
      "Dev Iteration 12000 complete. Mean Loss: 3.8085499123805424; Mean Acc:0.28811532258987427; Time taken (s): 0.495983362197876\n",
      "Dev Iteration 12500 complete. Mean Loss: 3.809868222331535; Mean Acc:0.28782573342323303; Time taken (s): 0.50734543800354\n",
      "Dev Iteration 13000 complete. Mean Loss: 3.8198951678994564; Mean Acc:0.28661736845970154; Time taken (s): 0.5071179866790771\n",
      "Dev Iteration 13500 complete. Mean Loss: 3.8266219404677746; Mean Acc:0.28580522537231445; Time taken (s): 0.5047070980072021\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev Iteration 14000 complete. Mean Loss: 3.829045092469496; Mean Acc:0.2853468060493469; Time taken (s): 0.508864164352417\n",
      "Dev Iteration 14500 complete. Mean Loss: 3.8307474189836825; Mean Acc:0.2851031720638275; Time taken (s): 0.5069327354431152\n",
      "Dev Iteration 15000 complete. Mean Loss: 3.8360246217900076; Mean Acc:0.28438103199005127; Time taken (s): 0.5189480781555176\n",
      "Dev Iteration 15500 complete. Mean Loss: 3.842446598043196; Mean Acc:0.2835633456707001; Time taken (s): 0.4975090026855469\n",
      "Epoch 1 complete! Development Accuracy: 0.2835707366466522; Development Loss: 3.8425192318297747\n",
      "\n",
      "--- Training model Epoch: 3 ---\n",
      "Training Iteration 0 of epoch 2 complete. Loss: 4.33746862411499; Acc:0.171875; Time taken (s): 0.3113560676574707\n",
      "Training Iteration 500 of epoch 2 complete. Loss: 2.858914375305176; Acc:0.421875; Time taken (s): 0.8285279273986816\n",
      "\n",
      "--- Evaluating model on dev data ---\n",
      "Dev Iteration 0 complete. Mean Loss: 3.6360301971435547; Mean Acc:0.296875; Time taken (s): 0.288196325302124\n",
      "Dev Iteration 500 complete. Mean Loss: 3.8546910359711943; Mean Acc:0.2989021837711334; Time taken (s): 0.5031867027282715\n",
      "Dev Iteration 1000 complete. Mean Loss: 3.951597623534493; Mean Acc:0.2853708565235138; Time taken (s): 0.5536513328552246\n",
      "Dev Iteration 1500 complete. Mean Loss: 3.978648657881364; Mean Acc:0.28198909759521484; Time taken (s): 0.553462028503418\n",
      "Dev Iteration 2000 complete. Mean Loss: 3.933822584831375; Mean Acc:0.28605228662490845; Time taken (s): 0.5610682964324951\n",
      "Dev Iteration 2500 complete. Mean Loss: 3.8975495166751872; Mean Acc:0.2895466685295105; Time taken (s): 0.5159664154052734\n",
      "Dev Iteration 3000 complete. Mean Loss: 3.8965747448175363; Mean Acc:0.289960652589798; Time taken (s): 0.5389208793640137\n",
      "Dev Iteration 3500 complete. Mean Loss: 3.8682429930442606; Mean Acc:0.29227811098098755; Time taken (s): 0.5286190509796143\n",
      "Dev Iteration 4000 complete. Mean Loss: 3.862530701787911; Mean Acc:0.2938757538795471; Time taken (s): 0.5098378658294678\n",
      "Dev Iteration 4500 complete. Mean Loss: 3.864559862328169; Mean Acc:0.2940041124820709; Time taken (s): 0.5651202201843262\n",
      "Dev Iteration 5000 complete. Mean Loss: 3.8578702948422845; Mean Acc:0.29492226243019104; Time taken (s): 0.503704309463501\n",
      "Dev Iteration 5500 complete. Mean Loss: 3.8489875356796937; Mean Acc:0.2951849699020386; Time taken (s): 0.5069541931152344\n",
      "Dev Iteration 6000 complete. Mean Loss: 3.85093478545847; Mean Acc:0.29473215341567993; Time taken (s): 0.6418302059173584\n",
      "Dev Iteration 6500 complete. Mean Loss: 3.8426204504297066; Mean Acc:0.29540887475013733; Time taken (s): 0.5528686046600342\n",
      "Dev Iteration 7000 complete. Mean Loss: 3.8436851723673273; Mean Acc:0.2952658534049988; Time taken (s): 0.5046391487121582\n",
      "Dev Iteration 7500 complete. Mean Loss: 3.8434610132089757; Mean Acc:0.2950606346130371; Time taken (s): 0.49318528175354004\n",
      "Dev Iteration 8000 complete. Mean Loss: 3.8413040774894527; Mean Acc:0.29505297541618347; Time taken (s): 0.5069355964660645\n",
      "Dev Iteration 8500 complete. Mean Loss: 3.8453545753934244; Mean Acc:0.29486972093582153; Time taken (s): 0.4943523406982422\n",
      "Dev Iteration 9000 complete. Mean Loss: 3.8506043938289363; Mean Acc:0.2944672703742981; Time taken (s): 0.47312331199645996\n",
      "Dev Iteration 9500 complete. Mean Loss: 3.83224073274175; Mean Acc:0.29621389508247375; Time taken (s): 0.4953122138977051\n",
      "Dev Iteration 10000 complete. Mean Loss: 3.821912146475229; Mean Acc:0.29716089367866516; Time taken (s): 0.505671501159668\n",
      "Dev Iteration 10500 complete. Mean Loss: 3.8252040168442347; Mean Acc:0.2968110144138336; Time taken (s): 0.49851107597351074\n",
      "Dev Iteration 11000 complete. Mean Loss: 3.8299451325657303; Mean Acc:0.2966846823692322; Time taken (s): 0.5225088596343994\n",
      "Dev Iteration 11500 complete. Mean Loss: 3.819914540180216; Mean Acc:0.29775944352149963; Time taken (s): 0.5290875434875488\n",
      "Dev Iteration 12000 complete. Mean Loss: 3.815661752068016; Mean Acc:0.297834575176239; Time taken (s): 0.5014512538909912\n",
      "Dev Iteration 12500 complete. Mean Loss: 3.817173995596725; Mean Acc:0.297553688287735; Time taken (s): 0.5029091835021973\n",
      "Dev Iteration 13000 complete. Mean Loss: 3.8274018983548994; Mean Acc:0.29631856083869934; Time taken (s): 0.5829627513885498\n",
      "Dev Iteration 13500 complete. Mean Loss: 3.8342705406300994; Mean Acc:0.2955498695373535; Time taken (s): 0.5941712856292725\n",
      "Dev Iteration 14000 complete. Mean Loss: 3.836828056663013; Mean Acc:0.29517534375190735; Time taken (s): 0.5090906620025635\n",
      "Dev Iteration 14500 complete. Mean Loss: 3.838648129204998; Mean Acc:0.2949516475200653; Time taken (s): 0.5103983879089355\n",
      "Dev Iteration 15000 complete. Mean Loss: 3.8441989091815696; Mean Acc:0.2942053973674774; Time taken (s): 0.5066821575164795\n",
      "Dev Iteration 15500 complete. Mean Loss: 3.850775234830448; Mean Acc:0.29343873262405396; Time taken (s): 0.5374755859375\n",
      "Epoch 2 complete! Development Accuracy: 0.2934911847114563; Development Loss: 3.8507187198105775\n",
      "Best development accuracy improved from 0.29127922654151917 to 0.2934911847114563, saving model...\n",
      "\n",
      "--- Training model Epoch: 4 ---\n",
      "Training Iteration 0 of epoch 3 complete. Loss: 3.9670329093933105; Acc:0.203125; Time taken (s): 0.29677462577819824\n",
      "Training Iteration 500 of epoch 3 complete. Loss: 2.816509962081909; Acc:0.421875; Time taken (s): 0.9632551670074463\n",
      "\n",
      "--- Evaluating model on dev data ---\n",
      "Dev Iteration 0 complete. Mean Loss: 3.5703887939453125; Mean Acc:0.296875; Time taken (s): 0.3001723289489746\n",
      "Dev Iteration 500 complete. Mean Loss: 3.8686443564896575; Mean Acc:0.3007734417915344; Time taken (s): 0.4978940486907959\n",
      "Dev Iteration 1000 complete. Mean Loss: 3.968126204106715; Mean Acc:0.28699424862861633; Time taken (s): 0.4330410957336426\n",
      "Dev Iteration 1500 complete. Mean Loss: 3.9964704140276215; Mean Acc:0.2833527624607086; Time taken (s): 0.4918067455291748\n",
      "Dev Iteration 2000 complete. Mean Loss: 3.950792657203045; Mean Acc:0.2877623736858368; Time taken (s): 0.4916088581085205\n",
      "Dev Iteration 2500 complete. Mean Loss: 3.913644488264875; Mean Acc:0.29110854864120483; Time taken (s): 0.49402952194213867\n",
      "Dev Iteration 3000 complete. Mean Loss: 3.9129257091717973; Mean Acc:0.29126229882240295; Time taken (s): 0.4803321361541748\n",
      "Dev Iteration 3500 complete. Mean Loss: 3.884115338563851; Mean Acc:0.29394280910491943; Time taken (s): 0.4859921932220459\n",
      "Dev Iteration 4000 complete. Mean Loss: 3.878353432696094; Mean Acc:0.29582059383392334; Time taken (s): 0.5034708976745605\n",
      "Dev Iteration 4500 complete. Mean Loss: 3.880571577660748; Mean Acc:0.2958231568336487; Time taken (s): 0.5317432880401611\n",
      "Dev Iteration 5000 complete. Mean Loss: 3.873469880141632; Mean Acc:0.2965906858444214; Time taken (s): 0.5668578147888184\n",
      "Dev Iteration 5500 complete. Mean Loss: 3.8643964232368657; Mean Acc:0.2967897951602936; Time taken (s): 0.6037516593933105\n",
      "Dev Iteration 6000 complete. Mean Loss: 3.8664530183728227; Mean Acc:0.2961850166320801; Time taken (s): 0.5055501461029053\n",
      "Dev Iteration 6500 complete. Mean Loss: 3.857815692689195; Mean Acc:0.29679808020591736; Time taken (s): 0.5119662284851074\n",
      "Dev Iteration 7000 complete. Mean Loss: 3.8585902838822075; Mean Acc:0.296529084444046; Time taken (s): 0.5377073287963867\n",
      "Dev Iteration 7500 complete. Mean Loss: 3.8583280040238512; Mean Acc:0.29629796743392944; Time taken (s): 0.7028882503509521\n",
      "Dev Iteration 8000 complete. Mean Loss: 3.8561894104877363; Mean Acc:0.2962246835231781; Time taken (s): 0.6176087856292725\n",
      "Dev Iteration 8500 complete. Mean Loss: 3.8605209197062433; Mean Acc:0.29593393206596375; Time taken (s): 0.5079238414764404\n",
      "Dev Iteration 9000 complete. Mean Loss: 3.865852695030049; Mean Acc:0.2956320643424988; Time taken (s): 0.5735039710998535\n",
      "Dev Iteration 9500 complete. Mean Loss: 3.8469711767599564; Mean Acc:0.2975558638572693; Time taken (s): 0.5143342018127441\n",
      "Dev Iteration 10000 complete. Mean Loss: 3.83616692373102; Mean Acc:0.29861700534820557; Time taken (s): 0.5467329025268555\n",
      "Dev Iteration 10500 complete. Mean Loss: 3.83969755248108; Mean Acc:0.298348069190979; Time taken (s): 0.5352025032043457\n",
      "Dev Iteration 11000 complete. Mean Loss: 3.844645412496389; Mean Acc:0.2981518805027008; Time taken (s): 0.5252456665039062\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev Iteration 11500 complete. Mean Loss: 3.8344505878233224; Mean Acc:0.2992457151412964; Time taken (s): 0.5461792945861816\n",
      "Dev Iteration 12000 complete. Mean Loss: 3.8301251543113546; Mean Acc:0.2992263734340668; Time taken (s): 0.6074256896972656\n",
      "Dev Iteration 12500 complete. Mean Loss: 3.8316258083829; Mean Acc:0.29886358976364136; Time taken (s): 0.5772831439971924\n",
      "Dev Iteration 13000 complete. Mean Loss: 3.8421757816855755; Mean Acc:0.297604501247406; Time taken (s): 0.6942884922027588\n",
      "Dev Iteration 13500 complete. Mean Loss: 3.8492774905103126; Mean Acc:0.29680439829826355; Time taken (s): 0.5990550518035889\n",
      "Dev Iteration 14000 complete. Mean Loss: 3.851756470210722; Mean Acc:0.2963995933532715; Time taken (s): 0.6385955810546875\n",
      "Dev Iteration 14500 complete. Mean Loss: 3.853557436410809; Mean Acc:0.29614338278770447; Time taken (s): 0.5067455768585205\n",
      "Dev Iteration 15000 complete. Mean Loss: 3.8593542609689364; Mean Acc:0.29535531997680664; Time taken (s): 0.572192907333374\n",
      "Dev Iteration 15500 complete. Mean Loss: 3.8662590661223306; Mean Acc:0.29452231526374817; Time taken (s): 0.519707202911377\n",
      "Epoch 3 complete! Development Accuracy: 0.2945219576358795; Development Loss: 3.866117418306694\n",
      "Best development accuracy improved from 0.2934911847114563 to 0.2945219576358795, saving model...\n",
      "\n",
      "--- Training model Epoch: 5 ---\n",
      "Training Iteration 0 of epoch 4 complete. Loss: 3.6537182331085205; Acc:0.25; Time taken (s): 0.3070974349975586\n",
      "Training Iteration 500 of epoch 4 complete. Loss: 2.779921770095825; Acc:0.40625; Time taken (s): 0.9147603511810303\n",
      "\n",
      "--- Evaluating model on dev data ---\n",
      "Dev Iteration 0 complete. Mean Loss: 3.5594046115875244; Mean Acc:0.3125; Time taken (s): 0.2995016574859619\n",
      "Dev Iteration 500 complete. Mean Loss: 3.9091573318321546; Mean Acc:0.2984967529773712; Time taken (s): 0.49350666999816895\n",
      "Dev Iteration 1000 complete. Mean Loss: 4.0094219378300835; Mean Acc:0.2849026024341583; Time taken (s): 0.49843764305114746\n",
      "Dev Iteration 1500 complete. Mean Loss: 4.038198769847049; Mean Acc:0.28146860003471375; Time taken (s): 0.4824061393737793\n",
      "Dev Iteration 2000 complete. Mean Loss: 3.991164926169575; Mean Acc:0.2857789993286133; Time taken (s): 0.46059107780456543\n",
      "Dev Iteration 2500 complete. Mean Loss: 3.9530891272031226; Mean Acc:0.2890343964099884; Time taken (s): 0.4570882320404053\n",
      "Dev Iteration 3000 complete. Mean Loss: 3.9526630745296356; Mean Acc:0.28910157084465027; Time taken (s): 0.4594435691833496\n",
      "Dev Iteration 3500 complete. Mean Loss: 3.9237387855881725; Mean Acc:0.2921486794948578; Time taken (s): 0.4692833423614502\n",
      "Dev Iteration 4000 complete. Mean Loss: 3.917654936088976; Mean Acc:0.2943131625652313; Time taken (s): 0.4709765911102295\n",
      "Dev Iteration 4500 complete. Mean Loss: 3.9196321582878944; Mean Acc:0.2940770089626312; Time taken (s): 0.48561930656433105\n",
      "Dev Iteration 5000 complete. Mean Loss: 3.9121964407834833; Mean Acc:0.2947254180908203; Time taken (s): 0.4926788806915283\n",
      "Dev Iteration 5500 complete. Mean Loss: 3.9029630434077514; Mean Acc:0.29503726959228516; Time taken (s): 0.48224782943725586\n",
      "Dev Iteration 6000 complete. Mean Loss: 3.9050450193506543; Mean Acc:0.29431554675102234; Time taken (s): 0.48181748390197754\n",
      "Dev Iteration 6500 complete. Mean Loss: 3.89588677602591; Mean Acc:0.294935405254364; Time taken (s): 0.4824535846710205\n",
      "Dev Iteration 7000 complete. Mean Loss: 3.896188034702754; Mean Acc:0.2945539057254791; Time taken (s): 0.5022416114807129\n",
      "Dev Iteration 7500 complete. Mean Loss: 3.8956241007249144; Mean Acc:0.29417118430137634; Time taken (s): 0.49083828926086426\n",
      "Dev Iteration 8000 complete. Mean Loss: 3.893405345808996; Mean Acc:0.2939241826534271; Time taken (s): 0.49912357330322266\n",
      "Dev Iteration 8500 complete. Mean Loss: 3.897936944470183; Mean Acc:0.29386985301971436; Time taken (s): 0.4895436763763428\n",
      "Dev Iteration 9000 complete. Mean Loss: 3.9032077137171832; Mean Acc:0.29375556111335754; Time taken (s): 0.49054908752441406\n",
      "Dev Iteration 9500 complete. Mean Loss: 3.8842072098923413; Mean Acc:0.29570573568344116; Time taken (s): 0.48686790466308594\n",
      "Dev Iteration 10000 complete. Mean Loss: 3.87316098230837; Mean Acc:0.2969453036785126; Time taken (s): 0.497847318649292\n",
      "Dev Iteration 10500 complete. Mean Loss: 3.8768213403507614; Mean Acc:0.2966354489326477; Time taken (s): 0.4980285167694092\n",
      "Dev Iteration 11000 complete. Mean Loss: 3.8818025659424706; Mean Acc:0.29647162556648254; Time taken (s): 0.4971325397491455\n",
      "Dev Iteration 11500 complete. Mean Loss: 3.8714452431664426; Mean Acc:0.297569215297699; Time taken (s): 0.5290579795837402\n",
      "Dev Iteration 12000 complete. Mean Loss: 3.867175817092293; Mean Acc:0.29761841893196106; Time taken (s): 0.4911065101623535\n",
      "Dev Iteration 12500 complete. Mean Loss: 3.8687241342714067; Mean Acc:0.29723498225212097; Time taken (s): 0.5015814304351807\n",
      "Dev Iteration 13000 complete. Mean Loss: 3.8796178765704417; Mean Acc:0.295918345451355; Time taken (s): 0.5068953037261963\n",
      "Dev Iteration 13500 complete. Mean Loss: 3.8871165235063234; Mean Acc:0.2950892448425293; Time taken (s): 0.492626428604126\n",
      "Dev Iteration 14000 complete. Mean Loss: 3.889611564391971; Mean Acc:0.2946619987487793; Time taken (s): 0.48868560791015625\n",
      "Dev Iteration 14500 complete. Mean Loss: 3.8915531770104943; Mean Acc:0.29435256123542786; Time taken (s): 0.49570226669311523\n",
      "Dev Iteration 15000 complete. Mean Loss: 3.897589037143567; Mean Acc:0.2935991883277893; Time taken (s): 0.4865121841430664\n",
      "Dev Iteration 15500 complete. Mean Loss: 3.904734160206286; Mean Acc:0.29271697998046875; Time taken (s): 0.48584508895874023\n",
      "Epoch 4 complete! Development Accuracy: 0.29272153973579407; Development Loss: 3.904538819743848\n"
     ]
    }
   ],
   "source": [
    "loss_function = nn.NLLLoss()\n",
    "\n",
    "# create model\n",
    "model = TrigramNNmodel(len(vocab), EMBEDDING_DIM, CONTEXT_SIZE, H)\n",
    "\n",
    "# load it to gpu\n",
    "model.cuda(gpu)\n",
    "\n",
    "# using ADAM optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr = 2e-3)\n",
    "\n",
    "\n",
    "# ------------------------- TRAIN & SAVE MODEL ------------------------\n",
    "best_acc = 0\n",
    "best_model_path = None\n",
    "for epoch in range(5):\n",
    "    st = time.time()\n",
    "    print(\"\\n--- Training model Epoch: {} ---\".format(epoch+1))\n",
    "    for it, data_tensor in enumerate(train_loader):       \n",
    "        context_tensor = data_tensor[:,0:2]\n",
    "        target_tensor = data_tensor[:,2]\n",
    "\n",
    "        context_tensor, target_tensor = context_tensor.cuda(gpu), target_tensor.cuda(gpu)\n",
    "\n",
    "        # zero out the gradients from the old instance\n",
    "        model.zero_grad()\n",
    "\n",
    "        # get log probabilities over next words\n",
    "        log_probs = model(context_tensor)\n",
    "\n",
    "        # calculate current accuracy\n",
    "        acc = get_accuracy_from_log_probs(log_probs, target_tensor)\n",
    "\n",
    "        # compute loss function\n",
    "        loss = loss_function(log_probs, target_tensor)\n",
    "\n",
    "        # backward pass and update gradient\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if it % 500 == 0: \n",
    "            print(\"Training Iteration {} of epoch {} complete. Loss: {}; Acc:{}; Time taken (s): {}\".format(it, epoch, loss.item(), acc, (time.time()-st)))\n",
    "            st = time.time()\n",
    "\n",
    "    print(\"\\n--- Evaluating model on dev data ---\")\n",
    "    dev_acc, dev_loss = evaluate(model, loss_function, dev_loader, gpu)\n",
    "    print(\"Epoch {} complete! Development Accuracy: {}; Development Loss: {}\".format(epoch, dev_acc, dev_loss))\n",
    "    if dev_acc > best_acc:\n",
    "        print(\"Best development accuracy improved from {} to {}, saving model...\".format(best_acc, dev_acc))\n",
    "        best_acc = dev_acc\n",
    "        # set best model path\n",
    "        best_model_path = 'best_model_{}.dat'.format(epoch)\n",
    "        # saving best model\n",
    "        torch.save(model.state_dict(), best_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e367548a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_model_0.dat  best_model_3.dat\t\t naive_bayes.ipynb\r\n",
      "best_model_2.dat  collaborative_filtering.ipynb  neural_plm.ipynb\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bcfec507",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{('computer', 'keyboard'): 1.0, ('cat', 'dog'): 0.022388342767953873, ('keyboard', 'cat'): 1.0, ('dog', 'car'): -0.03178047016263008}\n"
     ]
    }
   ],
   "source": [
    "# ---------------------- Loading Best Model -------------------\n",
    "best_model = TrigramNNmodel(len(vocab), EMBEDDING_DIM, CONTEXT_SIZE, H)\n",
    "best_model.load_state_dict(torch.load(best_model_path))\n",
    "best_model.cuda(gpu)\n",
    "\n",
    "cos = nn.CosineSimilarity(dim=0)\n",
    "\n",
    "lm_similarities = {}\n",
    "\n",
    "# word pairs to calculate similarity\n",
    "words = {('computer','keyboard'),('cat','dog'),('dog','car'),('keyboard','cat')}\n",
    "\n",
    "# ----------- Calculate LM similarities using cosine similarity ----------\n",
    "for word_pairs in words:\n",
    "    w1 = word_pairs[0]\n",
    "    w2 = word_pairs[1]\n",
    "    words_tensor = torch.LongTensor([get_id_of_word(w1),get_id_of_word(w2)])\n",
    "    words_tensor = words_tensor.cuda(gpu)\n",
    "    # get word embeddings from the best model\n",
    "    words_embeds = best_model.embeddings(words_tensor)\n",
    "    # calculate cosine similarity between word vectors\n",
    "    sim = cos(words_embeds[0],words_embeds[1])\n",
    "    lm_similarities[word_pairs] = sim.item()\n",
    "\n",
    "print(lm_similarities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd0fc3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1st layer: Linear, g()\n",
    "#2nd layer: Tanh, non-linearity\n",
    "#3rd Layer: Activation (ReLU or something)\n",
    "\n",
    "#TODO: Code this later in the notebook"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
