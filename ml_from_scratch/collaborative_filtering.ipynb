{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3829301b",
   "metadata": {},
   "source": [
    "# Collaborative Filtering from Scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2478a21",
   "metadata": {},
   "source": [
    "The goal is to implement a collaborative filtering algorithm from scratch. We should have the following progression:\\\n",
    "- User-Item Collaborative Filtering\n",
    "    - Basics\n",
    "    - CF algorithm\n",
    "    - Naive collaborative filtering with Alternating Least Squares\n",
    "    - Naive CF with SGD\n",
    "    - Updating a CF recommendation system\n",
    "- Item-Item Collaborative Filtering\n",
    "    - Basics\n",
    "    - Algorithm\n",
    "    - Implementation\n",
    "    - Notes\n",
    "- NN Collaborative Filtering\n",
    "    - Basics\n",
    "    - From Matrix Operations to NN\n",
    "    - Naive NNCF\n",
    "    - additional NNCF flavors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d7874f",
   "metadata": {},
   "source": [
    "#### Extras\n",
    "But modern CF models use neural networks...\n",
    "\n",
    "- NN for CF with side data\n",
    "- Bayesian CF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e528a3d2",
   "metadata": {},
   "source": [
    "#### A good flavor of CF: Tag-based CF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c82eb8",
   "metadata": {},
   "source": [
    "If we have time, we can make a more efficient recommendation system that's\n",
    "- more storage efficient\n",
    "- good for online training scenario"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70010191",
   "metadata": {},
   "source": [
    "### Basics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2fda54a",
   "metadata": {},
   "source": [
    "The recommender problem is one of **matrix completion**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ef0c8c",
   "metadata": {},
   "source": [
    "We start with a rating matrix $R$, which is $N$ x $M$ ($n$ users, $m$ items)\n",
    "\n",
    "Let's say our target is the predicted ratings  $\\hat{Y}_{ui} \\approx R$. Then our optimization problem becomes\n",
    "$$ \\mathcal{L}(Z) = \\sum_{ij:Y_{ij \\neq ?}} ||Z - Y||^2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e20a16dd",
   "metadata": {},
   "source": [
    "With some constraints, we can make the problem solvable:\n",
    "- $Y$ is low rank $\\rightarrow Z = UV^T \\approx Y$\n",
    "- We can map $U$ and $V$ pair-wise to latent variables $\\rightarrow U$ is [$N$ x $K$], $V$ is [$M$ x $K$]\n",
    "\n",
    "This also means we need to \"fill out\" $U$ and $V$.\n",
    "\n",
    "For basic collaborative filtering with matrices, we can do this with Alternating Least Squares (ALS).\n",
    "\n",
    "Formally, we have to solve $$argmin_{U, V}  (R - UV^T + C)$$\n",
    "where $C$ abbreviates the regularization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe341513",
   "metadata": {},
   "source": [
    "#### Simple ALS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45f956dd",
   "metadata": {},
   "source": [
    "We can solve the normal equations\n",
    "$$ U = (V V^T + \\lambda I)^{-1} V R$$\n",
    "$$ V = (U U^T + \\lambda I)^{-1} U R$$\n",
    "\n",
    "to minimize the RMSE for our reconstructed $R$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4728e6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5051cf48",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2 users, 3 items, 5 latents\n",
    "n = 2\n",
    "m = 3\n",
    "k = 5\n",
    "noise = 1e-4\n",
    "#Generates [2,3] array\n",
    "R = np.array([[0, 1, 0], [1, 1, 0]], dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b19fe0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Alternating Least Squares\n",
    "best_U = np.random.randn(n,k)\n",
    "best_Vt = np.random.randn(m,k)\n",
    "#We can do this in closed form\n",
    "\n",
    "#Solve for V first, by fixing U\n",
    "best_Vt = np.linalg.inv(best_U.T @ best_U + noise*np.eye(k)) @ best_U.T @ R\n",
    "#Solve for U, by fixing V\n",
    "best_U = (np.linalg.inv(best_Vt @ best_Vt.T + noise*np.eye(k)) @ best_Vt @ R.T).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "439e791b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00025311028536202575"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check RMSE\n",
    "np.sqrt(np.mean((R - (best_U @ best_Vt))**2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e8d034",
   "metadata": {},
   "source": [
    "This is linear ALS, we can improve our results with non-linear methods like PMF (Probabilistic Matrix Factorization) later."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8163908",
   "metadata": {},
   "source": [
    "#### ALS using Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a96b0aa",
   "metadata": {},
   "source": [
    "We can use Gradient Descent as well to generate our new $R$\n",
    "\n",
    "Let our loss function be \n",
    "$$\\mathcal{L}(R) = (R - U V^T)^2$$\n",
    "and $$ R = UV^T $$\n",
    "\n",
    "We solve for these so that we can apply the chain rule:\n",
    "$$ \\frac{\\partial\\mathcal{L}}{\\partial R} = 2 (R - UV^T)$$\n",
    "$$ \\frac{\\partial R}{\\partial U} = V$$\n",
    "$$ \\frac{\\partial R}{\\partial V} = U$$\n",
    "\n",
    "Then we get our gradients:\n",
    "$$ \\frac{\\partial\\mathcal{L}}{\\partial U} = \\frac{\\partial\\mathcal{L}}{\\partial R} \\frac{\\partial\\mathcal{R}}{\\partial U}$$\n",
    "\n",
    "\n",
    "$$ \\frac{\\partial\\mathcal{L}}{\\partial V} = \\frac{\\partial\\mathcal{L}}{\\partial R} \\frac{\\partial\\mathcal{R}}{\\partial V}$$\n",
    "\n",
    "For every parameter $\\theta$ and learning rate $\\alpha$, we update during each iteration $i$ (gradient descent):\n",
    "$$ \\theta_{i+1} = \\theta_i - \\alpha \\frac{\\partial\\mathcal{L}}{\\partial \\theta}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "1a1a6afb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-4.45893958 -2.14089102  3.98616959]\n",
      " [ 6.86761432  1.71099814  2.86743179]]\n",
      "converged in 26 iterations\n",
      "[[ 3.06696587e-03  9.92514933e-01  3.92092960e-04]\n",
      " [ 9.99778792e-01  1.00053987e+00 -2.82800717e-05]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0.],\n",
       "       [1., 1., 0.]])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#TODO: Code here.\n",
    "lr = 0.05\n",
    "n_iter = 100\n",
    "best_U = np.random.randn(n,k)\n",
    "best_V = np.random.randn(m,k)\n",
    "print(best_U @ best_V.T)\n",
    "#Gradient Descent\n",
    "for _iter in range(n_iter):\n",
    "    #Solve for U\n",
    "    best_U  = best_U + lr*(2*(R - best_U @ best_V.T)@ best_V)\n",
    "    #Solve for V\n",
    "    best_V = best_V + lr*(2*(R - best_U @ best_V.T).T @ best_U)\n",
    "    if(np.linalg.norm(R - (best_U @ best_V.T)) < 1e-2):\n",
    "        print(\"converged in \" + str(_iter) + \" iterations\")\n",
    "        break\n",
    "print(best_U @ best_V.T)\n",
    "R"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea33160f",
   "metadata": {},
   "source": [
    "For the streaming case, we can selectively update each entry of $R_{ui}$ iteratively with SGD."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bd4080e",
   "metadata": {},
   "source": [
    "## Item-Item Collaborative Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e414c1a",
   "metadata": {},
   "source": [
    "In practice, item-item CF works better. Items are simpler than human beings (and change less often)\n",
    "\n",
    "Inputs:\n",
    "- User-Item Utility Matrix\n",
    "- Item Similarity Mappings\n",
    "\n",
    "Outputs:\n",
    "- Recommendation\n",
    "\n",
    "\n",
    "Steps:\n",
    "- Find arbitrary number of similar items to ones the user liked\n",
    "- Rank them and serve the top 3 (that user hasn't seen yet)\n",
    "\n",
    "\n",
    "#### Complexity\n",
    "Assume that we already have the utility matrix. Given $m$ items, we would have $O(m)$ complexity for 1 query from a user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b37f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Code here\n",
    "\n",
    "\n",
    "#Data initialization\n",
    "\n",
    "\n",
    "\n",
    "#Item Similarity Mappings\n",
    "\n",
    "\n",
    "\n",
    "#\n",
    "##Algorithm...\n",
    "#\n",
    "\n",
    "#Find similar items to each item user enjoyed\n",
    "\n",
    "\n",
    "#Rank and serve"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1fa15b5",
   "metadata": {},
   "source": [
    "## NN Collaborative Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcbeabdb",
   "metadata": {},
   "source": [
    "We can also use a neural network to implement a recommender system. TBD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50acbc34",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Code here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
